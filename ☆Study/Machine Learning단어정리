▶ epoch
: One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE

→ 한 번의 epoch는 인공 신경망에서 전체 데이터 셋에 대해 forward pass/backward pass 과정을 거친 것을 말함. 
  즉, [전체 데이터 셋에 대해 한 번 학습을 완료한 상태]

→ 신경망에서 사용되는 역전파 알고리즘(backpropagation algorithm)은 
  파라미터를 사용하여 입력부터 출력까지의 각 계층의 weight를 계산하는 과정을 거치는 순방향 패스(forward pass), 
  forward pass를 반대로 거슬러 올라가며 다시 한 번 계산 과정을 거처 기존의 weight를 수정하는 역방향 패스(backward pass)로 나뉩니다. 
  이 전체 데이터 셋에 대해 해당 과정(forward pass + backward pass)이 완료되면 한 번의 epoch가 진행됐다고 볼 수 있습니다.

→ epochs = 40이라면 전체 데이터를 40번 사용해서 학습을 거치는 것입니다.

→ 우리는 모델을 만들 때 적절한 epoch 값을 설정해야만 underfitting과 overfitting을 방지할 수 있습니다.
  epoch 값이 너무 작다면 underfitting이 
             너무 크다면 overfitting이 발생할 확률이 높은 것이죠.
             
▶ batch size
: Total number of training examples present in a single batch.

→ 한 번의 batch 마다 주는 데이터 샘플의  size

▶ batch
: 보통 mini batch라고 함
→ 나눠진 데이터 셋

▶ iteration
: The number of passes to complete one epoch.

→ epoch를 나누어서 실행하는 횟수

▷ 정리...
메모리의 한계와 속도 저하때문에 대부분의 경우에는 한 번의 epoch 에서 모든 데이터를 한꺼번에 집어넣을 수는 없습니다. 
그래서 데이터를 나누어서 주게 되는데 이 때!
  몇 번 나누어서 주는가를 iteration,
  각 iteration마다 주는 데이터 사이즈를 batch size라고 합니다. 
  
▷ 문제...
1) 
총 데이터 = 100
batch size = 10

그럼 1iteration = 10, 10개 데이터에 대해서 학습
1 epoch = 100/batch size = 10 iteratoin

2) 
총 데이터 = 2000
epochs = 20
batch size = 500

그럼 1iteration = 4

1epoch는 데이터 size가 500인 batch가 4번의 iteration으로 나누어집니다.

전체 데이터 셋을 20번 학습하므로
iteration입장에서는 80번 학습이 이
