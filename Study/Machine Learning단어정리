▶ 인공지능
→ 기계를 지능적으로 만드는 과학
→ AI 알고리즘은 자체 규칙 시스템을 구축

▶ 머신러닝
→ 정확한 결정을 내리기 위해 제공된 데이터를 통하여 스스로 학습할 수 있는 것입니다.
→ 빅데이터를 통한 학습 방법으로 머신러닝을 이용할 수 있습니다. 
→ 머신 러닝은 기본적으로 알고리즘을 이용해 데이터를 분석하고, 분석을 통해 학습하며, 학습한 내용을 기반으로 판단이나 예측을 합니다.
→ 의사 결정 기준에 대한 구체적인 지침을 소프트웨어에 직접 코딩해 넣는 것이 아닌, 
  대량의 데이터와 알고리즘을 통해 컴퓨터 그 자체를 ‘학습’시켜 작업 수행 방법을 익히는 것을 목표로 합니다.

▶ 딥러닝
→ 인공신경망에서 발전한 형태의 인공 지능
→ 뇌의 뉴런과 유사한 정보 입출력 계층을 활용해 데이터를 학습합니다.
→ Ex) 알파고, 종양식별 능력
(정확도 민감도 특이도 정밀도 재현율 을 다 따져서 딥러닝이 되는 것)

▷ 가장 큰 차이점은... 
딥러닝은 분류에 사용할 데이터를 스스로 학습할 수 있는 반면 
머신러닝은 학습 데이터를 수동으로 제공해야한다는점이 딥러닝과 머신러닝의 가장 큰 차이점입니다.

▷ 인공지능:가장 넓음 ) 머신러닝 ) 딥러닝 - 가장 좁음


▶ epoch
: One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE

→ 한 번의 epoch는 인공 신경망에서 전체 데이터 셋에 대해 forward pass/backward pass 과정을 거친 것을 말함. 
  즉, [전체 데이터 셋에 대해 한 번 학습을 완료한 상태]

→ 신경망에서 사용되는 역전파 알고리즘(backpropagation algorithm)은 
  파라미터를 사용하여 입력부터 출력까지의 각 계층의 weight를 계산하는 과정을 거치는 순방향 패스(forward pass), 
  forward pass를 반대로 거슬러 올라가며 다시 한 번 계산 과정을 거처 기존의 weight를 수정하는 역방향 패스(backward pass)로 나뉩니다. 
  이 전체 데이터 셋에 대해 해당 과정(forward pass + backward pass)이 완료되면 한 번의 epoch가 진행됐다고 볼 수 있습니다.

→ epochs = 40이라면 전체 데이터를 40번 사용해서 학습을 거치는 것입니다.

→ 우리는 모델을 만들 때 적절한 epoch 값을 설정해야만 underfitting과 overfitting을 방지할 수 있습니다.
  epoch 값이 너무 작다면 underfitting이 
             너무 크다면 overfitting이 발생할 확률이 높은 것이죠.
             
▶ batch size
: Total number of training examples present in a single batch.

→ 한 번의 batch 마다 주는 데이터 샘플의  size

▶ batch
: 보통 mini batch라고 함
→ 나눠진 데이터 셋

▶ iteration
: The number of passes to complete one epoch.

→ epoch를 나누어서 실행하는 횟수

▷ 정리...
메모리의 한계와 속도 저하때문에 대부분의 경우에는 한 번의 epoch 에서 모든 데이터를 한꺼번에 집어넣을 수는 없습니다. 
그래서 데이터를 나누어서 주게 되는데 이 때!
  몇 번 나누어서 주는가를 iteration,
  각 iteration마다 주는 데이터 사이즈를 batch size라고 합니다. 
  
▷ 문제...
1) 
총 데이터 = 100
batch size = 10

그럼 1iteration = 10, 10개 데이터에 대해서 학습
1 epoch = 100/batch size = 10 iteratoin

2) 
총 데이터 = 2000
epochs = 20
batch size = 500

그럼 1iteration = 4

1epoch는 데이터 size가 500인 batch가 4번의 iteration으로 나누어집니다.

전체 데이터 셋을 20번 학습하므로
iteration입장에서는 80번 학습이 이루어진 것이다.

※issues에 사진 참고!
